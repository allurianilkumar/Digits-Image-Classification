{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "<center>\n<h1>Multi-Classification</h1>\n<hr>\n<h2>Digits Image Classification </h2>\n<hr>\n</center>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Importing the dataset\nfrom sklearn.datasets import load_digits\n\ndigits = load_digits()\nprint(digits)",
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
            "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
            "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
            "       ...,\n",
            "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
            "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
            "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
            "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
            "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
            "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
            "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
            "\n",
            "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
            "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
            "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
            "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
            "\n",
            "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
            "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
            "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
            "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
            "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
            "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
            "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
            "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
            "\n",
            "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
            "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
            "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
            "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
            "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
            "\n",
            "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
            "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
            "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
            "        ...,\n",
            "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
            "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
            "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\ndigits.images[0].shape\nlist = [10,100,100,45]\nfig = plt.figure()\nfor i,j in enumerate(list):\n    plt.subplot(2,2,i+1)\n    plt.imshow(digits.images[j],cmap='gray')",
      "metadata": {},
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "# Preparing Data",
      "metadata": {},
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# Create feature and target arrays\nX =  digits.data\ny =  digits.target",
      "metadata": {},
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "print(digits.images.shape)\nprint(digits.data.shape)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1797, 8, 8)\n",
            "(1797, 64)\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "#Preparing Data",
      "metadata": {},
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "n_samples = len(digits.images)\ndata = digits.images.reshape((n_samples, -1))",
      "metadata": {},
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": "## Step 1. Split the dataset into training data and testing data (<mark>10 points</mark>)",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": "## Importing Relevant Libraries & Modules",
      "metadata": {},
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "from sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split",
      "metadata": {},
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": "<p>The next step is to use the train_test_split function to split our data into 50% training and 50% testing data.</p>",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_test, y_train, y_test = train_test_split(data, digits.target, test_size=0.5, shuffle=False)",
      "metadata": {},
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)",
      "metadata": {},
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": "## Step 2. Algorithm Analysis (<mark>80 points</mark>)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Method 1. KNN",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n# Fit the classifier to the training data\nknn.fit(X_train ,y_train)\ny_pred = knn.predict(X_test)\n#from sklearn.metrics import accuracy_score\n#accuracy_score(y_pred,y_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": "classifier is defined by using KNN classification algorithm KNN_classifier",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\nknn_accuracy_score =round(accuracy_score(y_test, y_pred),2)\nprint('Accuracy:', knn_accuracy_score)\n\n#precision_score\nfrom sklearn.metrics import precision_score\nknn_precision_score=round(precision_score(y_test, y_pred, average='weighted'),2)\nprint(\"Precision Score : \",knn_precision_score)\n\n#recall_score\nfrom sklearn.metrics import recall_score\nknn_recall_score=round(recall_score(y_test, y_pred, average='weighted'),2)\nprint(\"Recall Score : \",knn_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98\n",
            "Precision Score :  0.98\n",
            "Recall Score :  0.98\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "#classification_report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        36\n",
            "           1       0.95      1.00      0.97        36\n",
            "           2       1.00      1.00      1.00        35\n",
            "           3       1.00      1.00      1.00        37\n",
            "           4       0.97      1.00      0.99        36\n",
            "           5       1.00      1.00      1.00        37\n",
            "           6       1.00      0.97      0.99        36\n",
            "           7       0.97      1.00      0.99        36\n",
            "           8       0.94      0.91      0.93        35\n",
            "           9       1.00      0.94      0.97        36\n",
            "\n",
            "   micro avg       0.98      0.98      0.98       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier()\n# Fit the classifier to the training data\nknn.fit(X_train, y_train)\n# Print the accuracy\nprint(knn.score(X_test, y_test))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9833333333333333\n"
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\n# Setup arrays to store train and test accuracies\nneighbors = np.arange(1, 9)\ntrain_accuracy = np.empty(len(neighbors))\ntest_accuracy = np.empty(len(neighbors))",
      "metadata": {},
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": "<b>Finding a good k value</b>\n\nLet's now compute and plot the training and testing accuracy scores for a variety of different neighbor values. By observing how the accuracy scores differ for the training and testing sets with different values of k, you can develop an intuition for overfitting and underfitting a model.\n\nLet's now streamline some of the steps we did above into a for loop.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Loop over different values of k\nfor i, k in enumerate(neighbors):\n    # Setup a k-NN Classifier with k neighbors: knn\n    knn = KNeighborsClassifier(n_neighbors=k)\n\n    # Fit the classifier to the training data\n    knn.fit(X_train, y_train)\n    \n    #Compute accuracy on the training set\n    train_accuracy[i] = knn.score(X_train, y_train)\n\n    #Compute accuracy on the testing set\n    test_accuracy[i] = knn.score(X_test, y_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "# Generate plot\nplt.title('k-NN: Varying Number of Neighbors')\nplt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\nplt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\nplt.legend()\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.show()",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        36\n",
            "           1       0.95      1.00      0.97        36\n",
            "           2       1.00      1.00      1.00        35\n",
            "           3       1.00      1.00      1.00        37\n",
            "           4       0.97      1.00      0.99        36\n",
            "           5       1.00      1.00      1.00        37\n",
            "           6       1.00      0.97      0.99        36\n",
            "           7       0.97      1.00      0.99        36\n",
            "           8       0.94      0.91      0.93        35\n",
            "           9       1.00      0.94      0.97        36\n",
            "\n",
            "   micro avg       0.98      0.98      0.98       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "## Method 2. Linear SVM",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Creating our linear SVM object\nfrom sklearn.svm import SVC\nfrom sklearn import datasets, svm, metrics\nsvm=SVC(C=1,kernel=\"linear\")",
      "metadata": {},
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": "# Fitting the training data in the SVM object declaring before\nsvm.fit(X_train,y_train)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
              "  shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": "# Saving the predictions on the test set \ny_predict=svm.predict(X_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "# Measuring the accuracy of our predictions\nfrom sklearn import metrics\naccuracy=metrics.accuracy_score(y_test,y_predict)\nprint(accuracy)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9777777777777777\n"
          ]
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\nsvm_accuracy_score=round(accuracy_score(y_test, y_pred),2)\nprint('Accuracy:', svm_accuracy_score)\n\n#precision_score\nfrom sklearn.metrics import precision_score\nsvm_precision_score=round(precision_score(y_test, y_pred, average='weighted'),2)\nprint(\"Precision Score :\",svm_precision_score)\n\n#recall_score\nfrom sklearn.metrics import recall_score\nsvm_recall_score=round(recall_score(y_test, y_pred, average='weighted'),2)\nprint(\"Recall Score :\",svm_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.98\n",
            "Precision Score : 0.98\n",
            "Recall Score : 0.98\n"
          ]
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test,y_predict))\nprint(classification_report(y_test,y_predict))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[36  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 34  0  0  0  0  0  0  1  1]\n",
            " [ 0  0 35  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 36  0  0  0  0  0  1]\n",
            " [ 0  0  0  0 36  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 37  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 35  0  1  0]\n",
            " [ 0  0  0  0  0  0  0 36  0  0]\n",
            " [ 0  3  0  0  0  0  0  1 31  0]\n",
            " [ 0  0  0  0  0  0  0  0  0 36]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        36\n",
            "           1       0.92      0.94      0.93        36\n",
            "           2       1.00      1.00      1.00        35\n",
            "           3       1.00      0.97      0.99        37\n",
            "           4       1.00      1.00      1.00        36\n",
            "           5       1.00      1.00      1.00        37\n",
            "           6       1.00      0.97      0.99        36\n",
            "           7       0.97      1.00      0.99        36\n",
            "           8       0.94      0.89      0.91        35\n",
            "           9       0.95      1.00      0.97        36\n",
            "\n",
            "   micro avg       0.98      0.98      0.98       360\n",
            "   macro avg       0.98      0.98      0.98       360\n",
            "weighted avg       0.98      0.98      0.98       360\n",
            "\n"
          ]
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "## Method 3. Gaussian Kernal SVM",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "To use Gaussian kernel, you have to specify 'rbf' as value for the Kernel parameter of the SVC class.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.svm import SVC\ngsvm = SVC(kernel='rbf')\ngsvm.fit(X_train, y_train)",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
              "  shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "#Prediction and Evaluation\ny_pred = gsvm.predict(X_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\ngsvm_accuracy_score = round(accuracy_score(y_test, y_pred),2)\nprint('Accuracy :', gsvm_accuracy_score)\n\n#precision_score\nfrom sklearn.metrics import precision_score\ngsvm_precision_score= round(precision_score(y_test, y_pred, average='weighted'),2)\nprint(\"Precision Score : \",gsvm_precision_score)\n\n#recall_score\nfrom sklearn.metrics import recall_score\ngsvm_recall_score= round(recall_score(y_test, y_pred, average='weighted'),2)\nprint(\"Recall Score : \",gsvm_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.64\n",
            "Precision Score :  0.92\n",
            "Recall Score :  0.64\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[21  0  0  0  0 15  0  0  0  0]\n",
            " [ 0 22  0  0  0 14  0  0  0  0]\n",
            " [ 0  0 22  0  0 13  0  0  0  0]\n",
            " [ 0  0  0 32  0  5  0  0  0  0]\n",
            " [ 0  0  0  0 20 16  0  0  0  0]\n",
            " [ 0  0  0  0  0 37  0  0  0  0]\n",
            " [ 0  0  0  0  0 11 25  0  0  0]\n",
            " [ 0  0  0  0  0 18  0 18  0  0]\n",
            " [ 0  0  0  0  0 28  0  0  7  0]\n",
            " [ 0  0  0  0  0  8  0  0  0 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.58      0.74        36\n",
            "           1       1.00      0.61      0.76        36\n",
            "           2       1.00      0.63      0.77        35\n",
            "           3       1.00      0.86      0.93        37\n",
            "           4       1.00      0.56      0.71        36\n",
            "           5       0.22      1.00      0.37        37\n",
            "           6       1.00      0.69      0.82        36\n",
            "           7       1.00      0.50      0.67        36\n",
            "           8       1.00      0.20      0.33        35\n",
            "           9       1.00      0.78      0.88        36\n",
            "\n",
            "   micro avg       0.64      0.64      0.64       360\n",
            "   macro avg       0.92      0.64      0.70       360\n",
            "weighted avg       0.92      0.64      0.70       360\n",
            "\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": "## Method 4. Naive Bayes",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.naive_bayes import MultinomialNB\n\nnb = MultinomialNB()\n\nnb.fit(X_train, y_train)\n\ny_pred = nb.predict(X_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\nnb_accuracy_score =round(accuracy_score(y_test, y_pred),2)\nprint('Accuracy :', nb_accuracy_score)\n\n#precision_score\nfrom sklearn.metrics import precision_score\nnb_precision_score=round(precision_score(y_test, y_pred, average='weighted'),2)\nprint(\"Precision Score : \",nb_precision_score)\n\n#recall_score\nfrom sklearn.metrics import recall_score\nnb_recall_score=round(recall_score(y_test, y_pred, average='weighted'),2)\nprint(\"Recall Score : \",nb_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.89\n",
            "Precision Score :  0.89\n",
            "Recall Score :  0.89\n"
          ]
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[35  0  0  0  1  0  0  0  0  0]\n",
            " [ 0 23  5  0  0  1  1  0  2  4]\n",
            " [ 0  1 33  0  0  0  0  0  1  0]\n",
            " [ 0  0  1 36  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 36  0  0  0  0  0]\n",
            " [ 0  0  0  0  1 31  0  0  0  5]\n",
            " [ 0  1  0  0  0  0 34  0  1  0]\n",
            " [ 0  0  0  0  0  0  0 36  0  0]\n",
            " [ 0  6  0  0  0  0  0  1 28  0]\n",
            " [ 0  1  0  1  0  0  0  3  3 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        36\n",
            "           1       0.72      0.64      0.68        36\n",
            "           2       0.85      0.94      0.89        35\n",
            "           3       0.97      0.97      0.97        37\n",
            "           4       0.95      1.00      0.97        36\n",
            "           5       0.97      0.84      0.90        37\n",
            "           6       0.97      0.94      0.96        36\n",
            "           7       0.90      1.00      0.95        36\n",
            "           8       0.80      0.80      0.80        35\n",
            "           9       0.76      0.78      0.77        36\n",
            "\n",
            "   micro avg       0.89      0.89      0.89       360\n",
            "   macro avg       0.89      0.89      0.89       360\n",
            "weighted avg       0.89      0.89      0.89       360\n",
            "\n"
          ]
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "## Method 5. Decision Tree",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.tree import DecisionTreeClassifier \ndtree = DecisionTreeClassifier()\ndtree.fit(X_train , y_train)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
              "            splitter='best')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": "dtree.score(X_test , y_test)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8166666666666667"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": "#Prediction and Evaluation\ny_pred = dtree.predict(X_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": "y_test.shape",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(360,)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "y_pred.shape",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(360,)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\ndtree_accuracy_score =round(accuracy_score(y_test, y_pred),2)\nprint('Accuracy :', dtree_accuracy_score)\n\n#precision_score\nfrom sklearn.metrics import precision_score\ndtree_precision_score=round(precision_score(y_test, y_pred, average='weighted'),2)\nprint(\"Precision Score : \",dtree_precision_score)\n\n#recall_score\nfrom sklearn.metrics import recall_score\ndtree_recall_score=round(recall_score(y_test, y_pred, average='weighted'),2)\nprint(\"Recall Score : \",dtree_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.82\n",
            "Precision Score :  0.82\n",
            "Recall Score :  0.82\n"
          ]
        }
      ],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[35  0  0  0  0  0  0  0  1  0]\n",
            " [ 0 25  2  2  0  0  3  1  3  0]\n",
            " [ 1  0 28  2  0  0  0  0  4  0]\n",
            " [ 0  0  1 32  0  1  0  0  1  2]\n",
            " [ 1  1  0  0 31  0  2  0  1  0]\n",
            " [ 0  0  0  0  1 35  0  0  0  1]\n",
            " [ 0  2  0  0  0  2 31  0  1  0]\n",
            " [ 0  1  0  2  2  1  1 29  0  0]\n",
            " [ 0  5  0  1  0  2  2  2 21  2]\n",
            " [ 0  1  0  2  0  2  0  3  1 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        36\n",
            "           1       0.71      0.69      0.70        36\n",
            "           2       0.90      0.80      0.85        35\n",
            "           3       0.78      0.86      0.82        37\n",
            "           4       0.91      0.86      0.89        36\n",
            "           5       0.81      0.95      0.88        37\n",
            "           6       0.79      0.86      0.83        36\n",
            "           7       0.83      0.81      0.82        36\n",
            "           8       0.64      0.60      0.62        35\n",
            "           9       0.84      0.75      0.79        36\n",
            "\n",
            "   micro avg       0.82      0.82      0.82       360\n",
            "   macro avg       0.82      0.82      0.81       360\n",
            "weighted avg       0.82      0.82      0.82       360\n",
            "\n"
          ]
        }
      ],
      "execution_count": 39
    },
    {
      "cell_type": "markdown",
      "source": "## Method 6. Random Forest",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\n\nrf=RandomForestClassifier(random_state=42)\nrf.fit(X_train,y_train)\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 40
    },
    {
      "cell_type": "code",
      "source": "rf.fit(X_train , y_train)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": "rf.score(X_test, y_test)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9361111111111111"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": "y_pred= rf.predict(X_train)",
      "metadata": {},
      "outputs": [],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "source": "accuracy_score(y_train,rf.predict(X_train))",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9986082115518441"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\nrf_accuracy_score =round(accuracy_score(y_train, y_pred),2)\nprint('Accuracy :', rf_accuracy_score)\n",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 1.0\n"
          ]
        }
      ],
      "execution_count": 45
    },
    {
      "cell_type": "code",
      "source": "#precision_score\nfrom sklearn.metrics import precision_score\n# rf_precision_score=precision_score(y_train, y_pred)\nrf_precision_score = round(accuracy_score(y_train, y_pred),2)\nprint(\"Precision Score : \",rf_precision_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision Score :  1.0\n"
          ]
        }
      ],
      "execution_count": 46
    },
    {
      "cell_type": "code",
      "source": "# #recall_score\nfrom sklearn.metrics import recall_score\nrf_recall_score= round(recall_score(y_train, y_pred, average='weighted'),2)\nprint(\"Recall Score : \",rf_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recall Score :  1.0\n"
          ]
        }
      ],
      "execution_count": 47
    },
    {
      "cell_type": "markdown",
      "source": "## Method 7. Voting Classifier",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB",
      "metadata": {},
      "outputs": [],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": "clf1 = LogisticRegression(multi_class='multinomial', random_state=10)\nclf2 = RandomForestClassifier(n_estimators=50, random_state=10)\nclf3 = GaussianNB()",
      "metadata": {},
      "outputs": [],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": "voting = VotingClassifier(estimators=[('dtree', dtree), ('rf', rf), ('nb', nb)], voting='soft')",
      "metadata": {},
      "outputs": [],
      "execution_count": 50
    },
    {
      "cell_type": "code",
      "source": "voting = voting.fit(X_train, y_train)",
      "metadata": {},
      "outputs": [],
      "execution_count": 51
    },
    {
      "cell_type": "code",
      "source": "voting.score(X_test, y_test)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9416666666666667"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 52
    },
    {
      "cell_type": "code",
      "source": "#Prediction and Evaluation\ny_pred = dtree.predict(X_test)",
      "metadata": {},
      "outputs": [],
      "execution_count": 53
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\nvoting_accuracy_score = round(accuracy_score(y_test, y_pred),2)\nprint('Accuracy :', voting_accuracy_score)\n\n#precision_score\nfrom sklearn.metrics import precision_score\nvoting_precision_score= round(precision_score(y_test, y_pred, average='weighted'),2)\nprint(\"Precision Score : \",voting_precision_score)\n\n#recall_score\nfrom sklearn.metrics import recall_score\nvoting_recall_score= round(recall_score(y_test, y_pred, average='weighted'),2)\nprint(\"Recall Score : \",voting_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.82\n",
            "Precision Score :  0.82\n",
            "Recall Score :  0.82\n"
          ]
        }
      ],
      "execution_count": 54
    },
    {
      "cell_type": "markdown",
      "source": "## Method 8. Bagging",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from sklearn.ensemble import BaggingClassifier\nfrom sklearn.datasets import make_classification\nfrom sklearn.svm import SVC",
      "metadata": {},
      "outputs": [],
      "execution_count": 55
    },
    {
      "cell_type": "code",
      "source": "lr = LogisticRegression();\n# bnb = BernoulliNB()\ngnb = GaussianNB()\n\nbase_methods=[gnb]\nfor bm  in base_methods:\n print(\"Method: \", bm)\n bag_model=BaggingClassifier(base_estimator=bm,n_estimators=100,bootstrap=True)\n bag_model=bag_model.fit(X_train,y_train)\n y_test_pred=bag_model.predict(X_test)\n print(bag_model.score(X_test, y_test))\n print(confusion_matrix(y_test, y_test_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "0.8305555555555556\n",
            "[[33  0  0  0  2  1  0  0  0  0]\n",
            " [ 0 27  1  0  0  0  3  0  2  3]\n",
            " [ 0  2 22  0  0  0  0  0 11  0]\n",
            " [ 0  0  1 30  0  0  0  0  5  1]\n",
            " [ 0  1  0  0 29  0  1  4  1  0]\n",
            " [ 0  0  0  1  0 35  0  1  0  0]\n",
            " [ 0  1  0  0  0  0 35  0  0  0]\n",
            " [ 0  0  0  0  0  1  0 35  0  0]\n",
            " [ 0  4  0  1  0  0  0  1 29  0]\n",
            " [ 0  4  1  0  0  0  0  4  3 24]]\n"
          ]
        }
      ],
      "execution_count": 56
    },
    {
      "cell_type": "code",
      "source": "# performing predictions on the test dataset \ny_pred = bag_model.predict(X_test) ",
      "metadata": {},
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": "# metrics are used to find accuracy or error \nfrom sklearn import metrics\n# using metrics module for accuracy calculation \nprint(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACCURACY OF THE MODEL:  0.8305555555555556\n"
          ]
        }
      ],
      "execution_count": 58
    },
    {
      "cell_type": "code",
      "source": "lr = LogisticRegression();\n# bnb = BernoulliNB()\ngnb = GaussianNB()\n\nbase_methods=[gnb]\nfor bm  in base_methods:\n    print(\"Method: \", bm)\n    bag_model=BaggingClassifier(base_estimator=bm,n_estimators=100,bootstrap=True)\n    bag_model=bag_model.fit(X_train,y_train)\n    y_test_pred=bag_model.predict(X_test)\n    print(bag_model.score(X_test, y_test))\n    print(confusion_matrix(y_test, y_test_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Method:  GaussianNB(priors=None, var_smoothing=1e-09)\n",
            "0.8361111111111111\n",
            "[[33  0  0  0  2  1  0  0  0  0]\n",
            " [ 0 28  1  0  0  0  1  0  3  3]\n",
            " [ 0  2 22  0  0  0  0  0 11  0]\n",
            " [ 0  0  1 30  0  0  0  0  5  1]\n",
            " [ 0  1  0  0 29  0  1  4  1  0]\n",
            " [ 0  0  0  1  0 36  0  0  0  0]\n",
            " [ 0  1  0  0  0  0 35  0  0  0]\n",
            " [ 0  0  0  0  0  1  0 35  0  0]\n",
            " [ 0  4  0  1  0  0  0  1 29  0]\n",
            " [ 0  4  1  0  0  0  0  4  3 24]]\n"
          ]
        }
      ],
      "execution_count": 59
    },
    {
      "cell_type": "code",
      "source": "lr = LogisticRegression();\n# bnb = BernoulliNB()\ngnb = GaussianNB()\n\nbase_methods=[gnb]\nbag_model=BaggingClassifier(base_estimator=bm,n_estimators=100,bootstrap=True)\nbag_model=bag_model.fit(X_train,y_train)\ny_test_pred=bag_model.predict(X_test)\n",
      "metadata": {},
      "outputs": [],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": "#accuracy_score\nfrom sklearn.metrics import accuracy_score\nbagging_accuracy_score =round(accuracy_score(y_test, y_pred),2)\nprint('Accuracy :', bagging_accuracy_score)\n\n#precision_score\nfrom sklearn.metrics import precision_score\nbagging_precision_score=round(precision_score(y_test, y_pred, average='weighted'),2)\nprint(\"Precision Score : \",bagging_precision_score)\n\n#recall_score\nfrom sklearn.metrics import recall_score\nbagging_recall_score=round(recall_score(y_test, y_pred, average='weighted'),2)\nprint(\"Recall Score : \",bagging_recall_score)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy : 0.83\n",
            "Precision Score :  0.85\n",
            "Recall Score :  0.83\n"
          ]
        }
      ],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import classification_report, confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[33  0  0  0  2  1  0  0  0  0]\n",
            " [ 0 27  1  0  0  0  3  0  2  3]\n",
            " [ 0  2 22  0  0  0  0  0 11  0]\n",
            " [ 0  0  1 30  0  0  0  0  5  1]\n",
            " [ 0  1  0  0 29  0  1  4  1  0]\n",
            " [ 0  0  0  1  0 35  0  1  0  0]\n",
            " [ 0  1  0  0  0  0 35  0  0  0]\n",
            " [ 0  0  0  0  0  1  0 35  0  0]\n",
            " [ 0  4  0  1  0  0  0  1 29  0]\n",
            " [ 0  4  1  0  0  0  0  4  3 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        36\n",
            "           1       0.69      0.75      0.72        36\n",
            "           2       0.88      0.63      0.73        35\n",
            "           3       0.94      0.81      0.87        37\n",
            "           4       0.94      0.81      0.87        36\n",
            "           5       0.95      0.95      0.95        37\n",
            "           6       0.90      0.97      0.93        36\n",
            "           7       0.78      0.97      0.86        36\n",
            "           8       0.57      0.83      0.67        35\n",
            "           9       0.86      0.67      0.75        36\n",
            "\n",
            "   micro avg       0.83      0.83      0.83       360\n",
            "   macro avg       0.85      0.83      0.83       360\n",
            "weighted avg       0.85      0.83      0.83       360\n",
            "\n"
          ]
        }
      ],
      "execution_count": 62
    },
    {
      "cell_type": "markdown",
      "source": "## Step 3: Accuracy Results Table (<mark>8 points</mark>)",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "code",
      "source": "from IPython.display import HTML, display",
      "metadata": {},
      "outputs": [],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "source": "data = [[\"\", \"KNN\", \"L_SVM\", \"RBF_SVM\", \"NB\",\"DT\",\"RF\",\"Voting\",\"Bagging\" ],\n        [\"Accuracy\",knn_accuracy_score,svm_accuracy_score, gsvm_accuracy_score, nb_accuracy_score,dtree_accuracy_score,rf_accuracy_score,voting_accuracy_score,bagging_accuracy_score],\n        [\"Weighted Precision\",knn_precision_score, svm_precision_score, gsvm_precision_score, nb_precision_score,dtree_precision_score,rf_precision_score,voting_precision_score,bagging_precision_score],\n        [\"Weighted Recall\",knn_recall_score, svm_recall_score, gsvm_recall_score, nb_recall_score,dtree_recall_score,rf_recall_score,voting_recall_score,bagging_recall_score]\n        ]\ndisplay(HTML('<center><h4>load_digits Database</h4><table><tr>{}</tr></table></center>'.format(\n       '</tr><tr>'.join(\n           '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) \n           for row in data)\n       )\n))",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<center><h4>load_digits Database</h4><table><tr><td></td><td>KNN</td><td>L_SVM</td><td>RBF_SVM</td><td>NB</td><td>DT</td><td>RF</td><td>Voting</td><td>Bagging</td></tr><tr><td>Accuracy</td><td>0.98</td><td>0.98</td><td>0.64</td><td>0.89</td><td>0.82</td><td>1.0</td><td>0.82</td><td>0.83</td></tr><tr><td>Weighted Precision</td><td>0.98</td><td>0.98</td><td>0.92</td><td>0.89</td><td>0.82</td><td>1.0</td><td>0.82</td><td>0.85</td></tr><tr><td>Weighted Recall</td><td>0.98</td><td>0.98</td><td>0.64</td><td>0.89</td><td>0.82</td><td>1.0</td><td>0.82</td><td>0.83</td></tr></table></center>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 64
    },
    {
      "cell_type": "markdown",
      "source": "## Step 4: Conclusion (<mark>2 Points</mark>)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<p> I have loaded the digits database and then calculated the accuracy Weighted, Precsion and Weighted Recall values  </p>\n<p>Based on the results, I have understand the Random Forest Algorithm is the best one from all alogirthm.  </p>",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<p>Confusion matrix and classification report are another tool to visualize the model performance.   </p>",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Best Accuracy Algorithms from hight accuracy values to low accuracy values list as follow\n<ol>\n    <li>Random Forest Algorithm</li>\n    <li>KNN and Linear SVM</li>\n    <li>NB</li>\n    <li>Bagging</li>\n    <li>Dession Tree and votting</li>\n    <li>RBF SVM </li>\n</ol>",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      }
    }
  ]
}